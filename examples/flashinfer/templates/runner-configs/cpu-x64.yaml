matcherConfig:
  exactMatch: true
  labelMatchers:
    - [self-hosted, linux, x64, cpu]
  priority: 1
fifo: true

runner_config:
  runner_os: linux
  runner_architecture: x64
  runner_name_prefix: flashinfer-cpu-x64-
  runner_run_as: ubuntu

  # Allow IMDSv1 for compatibility with existing scripts (task_show_node_info.sh)
  runner_metadata_options:
    instance_metadata_tags: "enabled"
    http_endpoint: "enabled"
    http_tokens: "optional"
    http_put_response_hop_limit: 2

  # Use Ubuntu-compatible user-data script
  userdata_template: ./templates/user-data.sh

  # Organization-level runners (shared across flashinfer-ai org)
  enable_organization_runners: true

  # Custom labels (added to default: self-hosted, linux, x64)
  runner_extra_labels:
    - cpu

  # Reuse mode (not ephemeral)
  enable_ephemeral_runners: false

  # Large instances for AOT compilation (300+ GiB memory, matching Jenkins' 300-520 GiB range)
  # Many instance types for maximum spot availability
  instance_types:
    # 512 GiB - r-series 16xlarge
    - r6a.16xlarge    # 64 vCPUs, 512 GiB (AMD EPYC)
    - r6i.16xlarge    # 64 vCPUs, 512 GiB (Intel)
    - r6id.16xlarge   # 64 vCPUs, 512 GiB (Intel, NVMe)
    - r6in.16xlarge   # 64 vCPUs, 512 GiB (Intel, network optimized)
    - r5.16xlarge     # 64 vCPUs, 512 GiB
    - r5a.16xlarge    # 64 vCPUs, 512 GiB (AMD)
    - r5b.16xlarge    # 64 vCPUs, 512 GiB (EBS optimized)
    - r5n.16xlarge    # 64 vCPUs, 512 GiB (network optimized)
    - r5d.16xlarge    # 64 vCPUs, 512 GiB (NVMe)
    - r5dn.16xlarge   # 64 vCPUs, 512 GiB (NVMe, network)
    - r5ad.16xlarge   # 64 vCPUs, 512 GiB (AMD, NVMe)
    - r7a.16xlarge    # 64 vCPUs, 512 GiB (AMD EPYC 4th gen)
    - r7i.16xlarge    # 64 vCPUs, 512 GiB (Intel Sapphire Rapids)
    - r7iz.16xlarge   # 64 vCPUs, 512 GiB (Intel, high freq)
    # 384 GiB - r-series 12xlarge
    - r6a.12xlarge    # 48 vCPUs, 384 GiB (AMD)
    - r6i.12xlarge    # 48 vCPUs, 384 GiB (Intel)
    - r6id.12xlarge   # 48 vCPUs, 384 GiB (Intel, NVMe)
    - r6in.12xlarge   # 48 vCPUs, 384 GiB (Intel, network)
    - r5.12xlarge     # 48 vCPUs, 384 GiB
    - r5a.12xlarge    # 48 vCPUs, 384 GiB (AMD)
    - r5b.12xlarge    # 48 vCPUs, 384 GiB (EBS optimized)
    - r5n.12xlarge    # 48 vCPUs, 384 GiB (network)
    - r5d.12xlarge    # 48 vCPUs, 384 GiB (NVMe)
    - r5dn.12xlarge   # 48 vCPUs, 384 GiB (NVMe, network)
    - r5ad.12xlarge   # 48 vCPUs, 384 GiB (AMD, NVMe)
    - r7a.12xlarge    # 48 vCPUs, 384 GiB (AMD EPYC 4th gen)
    - r7i.12xlarge    # 48 vCPUs, 384 GiB (Intel Sapphire Rapids)
    # 384 GiB - m-series 24xlarge (96 vCPUs)
    - m5.24xlarge     # 96 vCPUs, 384 GiB
    - m5a.24xlarge    # 96 vCPUs, 384 GiB (AMD)
    - m5n.24xlarge    # 96 vCPUs, 384 GiB (network)
    - m5d.24xlarge    # 96 vCPUs, 384 GiB (NVMe)
    - m5dn.24xlarge   # 96 vCPUs, 384 GiB (NVMe, network)
    - m5ad.24xlarge   # 96 vCPUs, 384 GiB (AMD, NVMe)
    - m6a.24xlarge    # 96 vCPUs, 384 GiB (AMD EPYC)
    - m6i.24xlarge    # 96 vCPUs, 384 GiB (Intel)
    - m6id.24xlarge   # 96 vCPUs, 384 GiB (Intel, NVMe)
    - m6in.24xlarge   # 96 vCPUs, 384 GiB (Intel, network)
    - m7a.24xlarge    # 96 vCPUs, 384 GiB (AMD EPYC 4th gen)
    - m7i.24xlarge    # 96 vCPUs, 384 GiB (Intel Sapphire Rapids)

  # Spot with on-demand failover
  instance_target_capacity_type: spot
  # Use "capacity-optimized" (same as Jenkins) - prioritizes capacity stability over price
  instance_allocation_strategy: capacity-optimized
  enable_on_demand_failover_for_errors:
    - InsufficientInstanceCapacity

  # Create service-linked role (only needed ONCE per AWS account)
  create_service_linked_role_spot: true

  # Scaling configuration
  runners_maximum_count: 50
  delay_webhook_event: 30
  scale_down_schedule_expression: "cron(*/5 * * * ? *)"
  minimum_running_time_in_minutes: 10
  runner_boot_time_in_minutes: 10

  # Keep 1 runner warm during work hours (PST 9am-6pm â‰ˆ UTC 17:00-02:00)
  idle_config:
    - cron: "* 17-23 * * 1-5"
      timeZone: "UTC"
      idleCount: 1
    - cron: "* 0-2 * * 2-6"
      timeZone: "UTC"
      idleCount: 1

  # Use Ubuntu 22.04 AMI
  ami:
    owners:
      - "099720109477"  # Canonical
    filter:
      name:
        - "ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"
      state:
        - available

  # Storage
  block_device_mappings:
    - device_name: /dev/sda1
      volume_size: 500
      volume_type: gp3
      delete_on_termination: true
      encrypted: true

  # Debugging & monitoring
  enable_ssm_on_runners: true
  enable_cloudwatch_agent: true

  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"

  # userdata_post_install is now handled by userdata_template
